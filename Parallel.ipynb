{
 "metadata": {
  "name": "",
  "signature": "sha256:a8ebe1ac45a155bdc378cdb36641560ff79da89ed4e05f09d82e4b8df119e02d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "import numpy as np\n",
      "from scipy.integrate import odeint\n",
      "from multiprocessing import Pool\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Embarrassingly Parallel Programming in Python\n",
      "==================\n",
      "\n",
      "### What is parallel programming?\n",
      "Most computers these days can do multiple things at once, using multiple *cores*.  This is great, as it allows your computer to do multiple things simultaneously, without tying up your computer.\n",
      "\n",
      "But sometimes, those extra cores in our computer are going to waste.  You're waiting for your stellar model to converge, and it's taking forever, but only 1 of 4 cores is actually doing any work.\n",
      "\n",
      "It'd be great to get some of those other cores to help out when it's needed. That won't be all the time, but for slow running code, there are ways you can easily cut runtime by half, with only minor modifications\n",
      "\n",
      "### What is \"Embarrassingly Parallel\" Programming?\n",
      "Basically, when you have lots of **independent** processes.  This is the simplest version of parallel programming, **but it also offers the most speedup**.\n",
      "\n",
      "**Good example**: Given the astrometry of a nearby star, I want to integrate its motion backwards 10<sup>4</sup> times, slightly varying its initial conditions each time. This will let me estimate how the uncertainty in its current position effects the uncertainty of how close it passed by the Sun.\n",
      "\n",
      "**Bad example**: Given a comoving box, filled with N<sub>bodies</sub>, where N<sub>bodies</sub>=10<sup>9</sup>, and cosmological initial conditions, what would you expect the local cosmic web to look like at z=0.\n",
      "\n",
      "The **good** example is good because it's independent.  You know the 10<sup>4</sup> initial conditions you want to test.  The **bad** example is bad because it's so dependent.  Each body depends on the location of every other body, and each time step depends on the previous timestep.\n",
      "\n",
      "There are times when you'll need something more complicated, rather than \"embarassingly easy,\" but even those tasks will often have steps that are \"embarrasingly parallel,\" so this is a good place to start.\n",
      "\n",
      "\n",
      "\n",
      "### This talk is meant to:\n",
      "- introduce to parallel programming:\n",
      "- show when it can make your research go faster\n",
      "- show that it can be easy in python\n",
      "\n",
      "\n",
      "### This talk **isn't** meant to:\n",
      "- be an indepth discussion of the inner workings\n",
      "- be a guide on parallel computing on distributed clusters\n",
      "\n",
      "Those topics are interesting, and could be important for your work, but I'm going to keep it simple for today.  At the end I'll add some other readings I've found helpful.\n",
      "\n",
      "Also, it should be noted that Python is an interpretted language, and behaves quite different than Fortan, C/C++, etc. Python has its own set of challenges, and the tools you use in compiled languages might not apply in Python."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Basic Concepts\n",
      "----------\n",
      "\n",
      "Before we jump into multiprocessing, it'll be good to start with a bit of background.\n",
      "\n",
      "Much of this is based on the *map - filter - reduce* model. It's neither perfect nor comprehensive, but it's a starting point.\n",
      "\n",
      "**Mapping** is when you start with a set of inputs, apply a function to them to return a different set of outputs. In linear algebra, a matrix is something that maps an input vector to an output vector. (E.g. a rotation matrix can rotate [map] a vector along $\\hat{x}$ to a vector along $\\hat{y}$).  For scalars, a function is what maps a scalar to a scalar. (E.g. cosmology calculators can map values of redshift, $z$ to luminosity distance, $D_L$.)\n",
      "\n",
      "In Python a **map** is a function which can be applied to a large number of inputs **element-wise**. In this way it's not too different from a simple for loop, or a list comprehension.\n",
      "\n",
      "A Python **filter** is then a function that allows you to filter out unwanted values.  Maybe you want to remove observing data when there was bad data. Maybe you want to remove data for a certain type of object.  A **filter** will take a list, and only return the values which pass your filtering function. \n",
      "\n",
      "Finally, a **reduce** function allows you to combine all your data into a single number, rather than a list of elements.  Maybe now that have a collection of good pixels, you want the total photometric flux and uncertainty. Maybe you want to integrate some value over your IMF.\n",
      "\n",
      "The archetypal program flow is this: you have some initial inputs listing what you want to process.  **Map** does the work for each of those elements. **Filter** lets you mask / remove unwanted results.  **Reduce** helps you combine it into a reduced value.  As always, the process is much more fluid in reality."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Map - Filter - Reduce Example\n",
      "Given a temperatures in Celcius"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getF(C):\n",
      "    return C*9./5 + 32\n",
      "\n",
      "def isFreezingF(F):\n",
      "    if F < 32:\n",
      "        return True\n",
      "    else:\n",
      "        return False # return 0 or False to be filtered out\n",
      "\n",
      "\n",
      "Cs = [-9.2, 6.5, -17.3, 37.8]\n",
      "\n",
      "Fs = map(getF, Cs)\n",
      "\n",
      "Freezing = filter(isFreezingF, Fs)\n",
      "num_freezing = len(Freezing)\n",
      "FreezingAverage = reduce(np.add, Freezing) / num_freezing\n",
      "\n",
      "\n",
      "print(\"Temperatures in C: \", Cs)\n",
      "print(\"Temperatures in F: \", Fs)\n",
      "print(\"Temperatures which are below freezing: \", Freezing)\n",
      "print(\"Average Temperature when it is freezing: \", FreezingAverage, \"F\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Temperatures in C:  [-9.2, 6.5, -17.3, 37.8]\n",
        "Temperatures in F:  [15.440000000000001, 43.7, 0.8599999999999959, 100.03999999999999]\n",
        "Temperatures which are below freezing:  [15.440000000000001, 0.8599999999999959]\n",
        "Average Temperature when it is freezing:  8.15 F\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Let's try a \"real\" problem.\n",
      "\n",
      "Given a potential:\n",
      "    $$ \\Phi = \\ln r + V(\\phi) = \\ln r + \\ln (1 - e \\cos \\phi) $$\n",
      "with an eccentricity $ e = .3 $, and a dimensionless energy $ E = -1 $, try integrating a number of test particles for a range of initial radii $ x_0 < x_\\mathrm{max} = \\frac{\\exp^{E}}{1 - e} \\approx 0.52$.\n",
      "\n",
      "I.e. integrate particles in the given potential with the initial conditions:\n",
      "$$ x_0 \\in (0, x_\\mathrm{max})$$\n",
      "$$ y_0 = 0 $$\n",
      "$$ \\dot{x}_0 = 0 $$\n",
      "$$ \\dot{y}_0 = \\sqrt{2 ( E - \\Phi) - \\dot{x_0}^2} $$\n",
      "\n",
      "This sounds like an excellent time to use this *map* framework.  We have a range of initial conditions, which have to get processed by the same potential with the same physics, and each integration is independent of all the rest."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eccentricity = .3\n",
      "Energy       = -1\n",
      "x_max        = np.exp(Energy) / (1 - eccentricity)\n",
      "\n",
      "#padding to be added to avoid scientifically interesting,\n",
      "#  but numerically problematic initial conditions\n",
      "padding      = .1\n",
      "x_0s         = np.linspace(padding, x_max - padding) \n",
      "\n",
      "\n",
      "def derivs(w, t, eccentricity):\n",
      "    x,y, v_x, v_y = w\n",
      "    \n",
      "    r = np.sqrt(x**2 + y**2)\n",
      "    denominator = r**2 - (eccentricity * x * r)\n",
      "\n",
      "    # Calculate accelerations    \n",
      "    a_x = -1*(x - eccentricity * r) / denominator\n",
      "    a_y = -1*y / denominator\n",
      "    \n",
      "    return [v_x, v_y, a_x, a_y]\n",
      "\n",
      "def integrate(x_0, eccentricity=eccentricity, hmax=.1, num_steps=100):\n",
      "    x_0 = x_0\n",
      "    y_0 = 0\n",
      "    v_x_0 = 0\n",
      "    v_y_0 = np.sqrt(2 *(Energy - (np.log(x_0 * (1-eccentricity)))))\n",
      "    \n",
      "    w_0 = [x_0, y_0, v_x_0, v_y_0]\n",
      "    \n",
      "    ts = np.linspace(0,100, num=num_steps)\n",
      "    ws = odeint(derivs, w_0, ts, args = (eccentricity,), hmax=hmax)\n",
      "    ## if this was real work, you'd want to save your results now\n",
      "    ##   or return ws, or do something before you lose your results\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Running these integrations -- For loop vs. Map\n",
      "How do the methods compare?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Serial example\n",
      "\n",
      "for x_0 in x_0s:\n",
      "    integrate(x_0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 10.2 s, sys: 32.3 ms, total: 10.2 s\n",
        "Wall time: 10.2 s\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Serial example\n",
      "\n",
      "result = map(integrate, x_0s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 10.2 s, sys: 68.4 ms, total: 10.3 s\n",
        "Wall time: 10.2 s\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A little better, but not by much...\n",
      "\n",
      "### Let's try in parallel\n",
      "First, check how many cores are available"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "nproc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now use the <code>multiprocessing.Pool</code> version of <code>map</code>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Parallel example\n",
      "\n",
      "pool = Pool(2) # initialize thread pool N threads\n",
      "pool.map(integrate, x_0s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 11.4 ms, sys: 4.02 ms, total: 15.4 ms\n",
        "Wall time: 6.46 s\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Parallel example\n",
      "\n",
      "pool = Pool(4) # initialize thread pool N threads\n",
      "pool.map(integrate, x_0s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 5.97 ms, sys: 12.1 ms, total: 18.1 ms\n",
        "Wall time: 5.16 s\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Parallel example\n",
      "\n",
      "pool = Pool(8) # initialize thread pool N threads\n",
      "pool.map(integrate, x_0s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 18.5 ms, sys: 16.1 ms, total: 34.6 ms\n",
        "Wall time: 4.86 s\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Parallel example\n",
      "\n",
      "pool = Pool(32) # initialize thread pool N threads\n",
      "pool.map(integrate, x_0s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 35.2 ms, sys: 68.4 ms, total: 104 ms\n",
        "Wall time: 5.14 s\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### What does this show?\n",
      "So we see that <code>pool.map</code> is much faster, and that as we use more threads, things speed up.  But there's a limit. If our computer only has 4 cores available, creating more than 4 threads isn't very useful. In some cases it can actually *add* administrative overhead, while not adding any computing power."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Beyond simple maps\n",
      "Using <code>pool.map</code> *requires* that you use *exactly* the same function on each input.  Often times we want a bit more flexibility.\n",
      "\n",
      "<code>apply_async</code> allows us to explicitly pass arbitrary inputs to arbitrary functions.  This can be cumbersome, but what you lose in elegance, you gain in flexibility.\n",
      "\n",
      "### Let's try an example where we change the potential, while keeping the initial condition fixed:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Serial example\n",
      "\n",
      "eccentricities = [.3, .4, .5, .6]\n",
      "result_list = []\n",
      "\n",
      "for e in eccentricities:\n",
      "    result = integrate(.2, eccentricity=e, hmax = .0005, num_steps = 100000)\n",
      "    result_list.append(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 9.21 s, sys: 274 ms, total: 9.48 s\n",
        "Wall time: 9.07 s\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Parallel example\n",
      "\n",
      "eccentricities = [.3, .4, .5, .6]\n",
      "result_list = []\n",
      "integration_list = []\n",
      "\n",
      "pool = Pool(4)\n",
      "\n",
      "for e in eccentricities:\n",
      "    integration = pool.apply_async(integrate, [.2], {\"eccentricity\" : e, \"hmax\" : .0005, \"num_steps\":100000} )\n",
      "    integration_list.append(integration)\n",
      "\n",
      "for integration in integration_list:\n",
      "    result = integration.get()\n",
      "    result_list.append(result)\n",
      "    \n",
      "pool.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 19.5 ms, sys: 12.2 ms, total: 31.7 ms\n",
        "Wall time: 4.15 s\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Why aren't things speeding up as fast as I'd expect?\n",
      "\n",
      "### Amdahl's Law\n",
      "At first, going from 1 core to 4 cores seems like it should give a 4x improvement, but in practice we never fully achieve that efficiency.\n",
      "\n",
      "**Amdahl's Law** basically states that parallelizing a certain aspect of your project will only save you as much time as that part would have taken.  If your project takes 1 hour to run, and you parallelize a portion that only took 30 seconds of that hour, your code is still going to take ~1 hour to run.\n",
      "\n",
      "Parallelization also tends to add *overhead*.  If done right, this overhead will be worth the overall speedup.  But things will work best if you make sure parallel processing is actually appropriate for what you're doing.\n",
      "\n",
      "## Examples of when to stay serial\n",
      "- when I have lots of small steps which **all depend on each other**\n",
      "- when I'm doing something **small + simple** which runs ~instantly (will the speed up be worth the extra time it takes to program?  Is the main source of slowness simply due to the overhead of python trying to read in my file, rather than actually running it?)\n",
      "- when I'm doing something **memory heavy** (<code>APLpy/Montage</code> eats up all my memory; if I try to process 4 images all at once, I'll need 4x the memory)\n",
      "\n",
      "\n",
      "# Further Reading\n",
      "Hat tip to http://chriskiehl.com/article/parallelism-in-one-line/, for a blog post that helped me get started with this.\n",
      "\n",
      "In C/C++/Fortran you can apply a similar parallel programming model called <code>OpenMP</code>.  Things work a little differently, but it's a good starting place for injecting easy parallelizations.  It requires *shared memory* though; things get more complicated when you want multiple computers to work together, each with their own memory.\n",
      "\n",
      "For applying similar concepts in C, I've liked this overview: http://gribblelab.org/CBootcamp/A2_Parallel_Programming_in_C.html. It's reasonably concise, while covering a lot of big topics, and giving a nubmer of simple working examples."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}